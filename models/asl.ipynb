{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a31045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ultralytics import YOLO\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "315b3520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d8cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\n",
    "    \"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\n",
    "    \"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\n",
    "    \"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e775fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = YOLO(\"yolo_models/asl_yolo_v8/weights/best.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4b62e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASLCNN(nn.Module):\n",
    "    def __init__(self, num_classes=26):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),     # 14√ó14\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),     # 7√ó7\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),     # 3√ó3\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 3 * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d720ccaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Computer Vision\\ASL Recognition\\asl_env\\Lib\\site-packages\\torch\\cuda\\__init__.py:287: UserWarning: \n",
      "NVIDIA GeForce RTX 5060 Laptop GPU with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90 compute_37.\n",
      "If you want to use the NVIDIA GeForce RTX 5060 Laptop GPU GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ASLCNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1152, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model = ASLCNN(num_classes=36).to(device)\n",
    "cnn_model.load_state_dict(torch.load(\n",
    "    \"d:/Computer Vision/ASL Recognition/models/cnn/asl_cnn.pth\",\n",
    "    map_location=device\n",
    "))\n",
    "cnn_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89bfef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),   # üî• FIX\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d3bde19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_cnn_image(image_path, conf_yolo=0.5):\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    results = yolo_model(image, conf=conf_yolo)[0]\n",
    "\n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        crop = image[y1:y2, x1:x2]\n",
    "\n",
    "        if crop.size == 0:\n",
    "            continue\n",
    "\n",
    "        crop_rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "        crop_pil = Image.fromarray(crop_rgb)\n",
    "        input_tensor = cnn_transform(crop_pil).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = cnn_model(input_tensor)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            conf_cnn, pred = torch.max(probs, 1)\n",
    "\n",
    "        label = class_names[pred.item()]\n",
    "\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            f\"{label} ({conf_cnn.item():.2f})\",\n",
    "            (x1, y1 - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.9,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9fd8cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Camera started\n",
      "Detected: Y\n",
      "Detected: P\n",
      "Detected: Y\n",
      "Detected: P\n",
      "Detected: Y\n",
      "Detected: P\n",
      "Detected: Y\n",
      "Detected: A\n",
      "Detected: J\n",
      "Detected: D\n",
      "Detected: L\n",
      "Detected: X\n",
      "Detected: A\n",
      "Detected: X\n",
      "Detected: A\n",
      "Detected: O\n",
      "Detected: J\n",
      "Detected: P\n",
      "Detected: Y\n",
      "Detected: O\n",
      "Detected: P\n",
      "Detected: J\n",
      "Detected: P\n",
      "Detected: F\n",
      "Detected: P\n",
      "Detected: H\n",
      "Detected: P\n",
      "üõë Exiting program\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import sys\n",
    "from torchvision import transforms\n",
    "last_letter = None\n",
    "\n",
    "# -------------------- MODELS --------------------\n",
    "cnn_model.eval()\n",
    "yolo_model.to(\"cpu\")          # keep CPU until everything is stable\n",
    "device = next(cnn_model.parameters()).device\n",
    "\n",
    "# -------------------- TRANSFORM --------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((28, 28)),   # ‚úÖ MUST BE 28\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                         [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "\n",
    "# -------------------- CAMERA --------------------\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)  # CAP_DSHOW fixes Windows issues\n",
    "window_name = \"ASL Detection\"\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Camera not opened\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"‚úÖ Camera started\")\n",
    "\n",
    "# -------------------- MAIN LOOP --------------------\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "    # ---------- YOLO ----------\n",
    "    results = yolo_model(frame, verbose=False)[0]\n",
    "\n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "        h, w, _ = frame.shape\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(w, x2), min(h, y2)\n",
    "\n",
    "        hand = frame[y1:y2, x1:x2]\n",
    "        if hand.size == 0:\n",
    "            continue\n",
    "\n",
    "        # BGR ‚Üí RGB\n",
    "        hand = cv2.cvtColor(hand, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # ---------- CNN ----------\n",
    "        hand_tensor = transform(hand).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = cnn_model(hand_tensor).argmax(dim=1).item()\n",
    "\n",
    "        label = class_names[pred]\n",
    "        current_letter = class_names[pred]\n",
    "\n",
    "        if current_letter != last_letter:\n",
    "            print(\"Detected:\", current_letter)\n",
    "            last_letter = current_letter\n",
    "\n",
    "\n",
    "        # ---------- DRAW ----------\n",
    "        label_text = f\"{class_names[pred]}\"\n",
    "\n",
    "        # Move text INSIDE the box to ensure visibility\n",
    "        text_x = max(x1, 10)\n",
    "        text_y = max(y1 + 30, 30)\n",
    "\n",
    "        # Solid background for text (VERY IMPORTANT)\n",
    "        (text_w, text_h), _ = cv2.getTextSize(\n",
    "            label_text,\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1,\n",
    "            2\n",
    "        )\n",
    "\n",
    "        cv2.rectangle(\n",
    "            frame,\n",
    "            (text_x, text_y - text_h - 10),\n",
    "            (text_x + text_w + 10, text_y),\n",
    "            (0, 0, 0),      # black background\n",
    "            -1\n",
    "        )\n",
    "\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            label_text,\n",
    "            (text_x + 5, text_y - 5),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1,\n",
    "            (0, 255, 0),    # bright green text\n",
    "            2,\n",
    "            cv2.LINE_AA\n",
    "        )\n",
    "\n",
    "        # Bounding box\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    cv2.imshow(window_name, frame)\n",
    "\n",
    "    # ---------- EXIT CONDITIONS ----------\n",
    "    # ESC key\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "    # Window close button (‚ùå)\n",
    "    if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "# -------------------- CLEAN EXIT --------------------\n",
    "print(\"üõë Exiting program\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "sys.exit(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
